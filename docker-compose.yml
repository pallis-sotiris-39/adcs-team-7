version: '3.9'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - sensor-network

  kafkaservice:
    image: confluentinc/cp-kafka:7.0.1
    container_name: kafkaservice
    ports:
    # To learn about configuring Kafka for access across networks see
    # https://www.confluent.io/blog/kafka-client-cannot-connect-to-broker-on-aws-on-docker-etc/
      - "29092:29092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafkaservice:9092,PLAINTEXT_INTERNAL://localhost:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    networks:
      - sensor-network

  init-kafka:
    image: confluentinc/cp-kafka:7.0.1
    depends_on:
      - kafkaservice
    networks:
      - sensor-network
    entrypoint: ['/bin/sh', '-c']
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafkaservice:9092 --list

      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server kafkaservice:9092 --create --if-not-exists --topic capy-broker --replication-factor 1 --partitions 2
      kafka-topics --bootstrap-server kafkaservice:9092 --create --if-not-exists --topic capy-daily --replication-factor 1 --partitions 2
      kafka-topics --bootstrap-server kafkaservice:9092 --create --if-not-exists --topic capy-late --replication-factor 1 --partitions 2

      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafkaservice:9092 --list
      "

  influxdb:
    container_name: influxdb
    image: docker.io/influxdb:latest
    environment:
      INFLUXDB_DB: "sensors"
      DOCKER_INFLUXDB_INIT_MODE: "setup"
      DOCKER_INFLUXDB_INIT_USERNAME: "capyuser"
      DOCKER_INFLUXDB_INIT_PASSWORD: "capypassword"
      INFLUXDB_ADMIN_USER: "capyuser"
      INFLUXDB_ADMIN_PASSWORD: "capypassword"
      DOCKER_INFLUXDB_INIT_ORG: "capybara"
      DOCKER_INFLUXDB_INIT_BUCKET: "sensorbucket"
      DOCKER_INFLUXDB_INIT_ADMIN_TOKEN: "secrettoken"
      INFLUXDB_HTTP_AUTH_ENABLED: "true"
    restart: on-failure:10
    volumes:
      - ./influxdb.conf:/etc/influxdb/influxdb.conf
    ports:
      - "8086:8086"
    networks:
      - sensor-network

  grafana:
    image: grafana/grafana
    container_name: grafana
    restart: always
    ports:
      - "3001:3000"
    volumes:
      - grafana-storage:/var/lib/grafana
      - ./grafana-provisioning/:/etc/grafana/provisioning
    depends_on:
      - influxdb
    environment:
      GF_SECURITY_ADMIN_USER: "capyuser"
      GF_SECURITY_ADMIN_PASSWORD: "capypassword"

  broker:
    container_name: broker
    build:
      context: ./
      dockerfile: ./broker/Dockerfile
    restart: unless-stopped
    depends_on:
      - kafkaservice
    ports:
      - "8080:8080"
    networks:
      - sensor-network

  streaming:
    container_name: streaming
    build:
      context: ./
      dockerfile: ./streaming/Dockerfile
    restart: unless-stopped
    depends_on:
      - kafkaservice
    networks:
      - sensor-network

  dbconnector:
    container_name: dbconnector
    build:
      context: ./
      dockerfile: ./dbconnector/Dockerfile
    restart: unless-stopped
    depends_on:
      - kafkaservice
      - influxdb
    networks:
      - sensor-network  

networks:
  sensor-network:
    driver: bridge

volumes:
  grafana-storage: